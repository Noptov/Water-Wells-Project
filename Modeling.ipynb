{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('data/traininglabels.csv')\n",
    "data = pd.read_csv('data/trainingdata.csv')\n",
    "\n",
    "wellsdf = pd.merge(labels, data, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "Per the rational in EDA notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells2 = wellsdf.copy()\n",
    "\n",
    "\n",
    "\n",
    "wells2 = wells2.drop(['funder', 'installer', 'scheme_name', 'public_meeting', 'scheme_management',\n",
    "                      'id', 'amount_tsh', 'num_private', 'permit', 'subvillage'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 31 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   status_group           59400 non-null  object \n",
      " 1   date_recorded          59400 non-null  object \n",
      " 2   gps_height             59400 non-null  int64  \n",
      " 3   longitude              59400 non-null  float64\n",
      " 4   latitude               59400 non-null  float64\n",
      " 5   wpt_name               59400 non-null  object \n",
      " 6   basin                  59400 non-null  object \n",
      " 7   region                 59400 non-null  object \n",
      " 8   region_code            59400 non-null  int64  \n",
      " 9   district_code          59400 non-null  int64  \n",
      " 10  lga                    59400 non-null  object \n",
      " 11  ward                   59400 non-null  object \n",
      " 12  population             59400 non-null  int64  \n",
      " 13  recorded_by            59400 non-null  object \n",
      " 14  construction_year      59400 non-null  int64  \n",
      " 15  extraction_type        59400 non-null  object \n",
      " 16  extraction_type_group  59400 non-null  object \n",
      " 17  extraction_type_class  59400 non-null  object \n",
      " 18  management             59400 non-null  object \n",
      " 19  management_group       59400 non-null  object \n",
      " 20  payment                59400 non-null  object \n",
      " 21  payment_type           59400 non-null  object \n",
      " 22  water_quality          59400 non-null  object \n",
      " 23  quality_group          59400 non-null  object \n",
      " 24  quantity               59400 non-null  object \n",
      " 25  quantity_group         59400 non-null  object \n",
      " 26  source                 59400 non-null  object \n",
      " 27  source_type            59400 non-null  object \n",
      " 28  source_class           59400 non-null  object \n",
      " 29  waterpoint_type        59400 non-null  object \n",
      " 30  waterpoint_type_group  59400 non-null  object \n",
      "dtypes: float64(2), int64(5), object(24)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "wells2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplify and convert date_recorded to year_recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells2.date_recorded = pd.to_datetime(wells2.date_recorded)\n",
    "wells2['year_recorded'] = pd.DatetimeIndex(wells2['date_recorded']).year\n",
    "wells2.drop('date_recorded', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construction year\n",
    "Remove rows with zero, average the remainder, set zeros in wells2 to that value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_year = wells2.drop(wells2[wells2.construction_year == 0].index) \n",
    "con_avg = con_year.construction_year.mean().round(0)\n",
    "\n",
    "wells2.construction_year.replace(0, con_avg, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Appropriate Numeric Columns to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells2[['region_code', 'district_code', 'construction_year', 'year_recorded']] = wells2[['region_code', 'district_code', 'construction_year', 'year_recorded']].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lat & Long\n",
    "The default value for longitude (0) is outside of Tanzania (40°29' E to 29°10' E), so it will be replaced by the mean longitude from the dataset.  While the default value for latitude is possible, it may skew our data more north (-2), so it will be replaced with the mean latitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = wells2.drop(wells2[wells2.longitude == 0].index) \n",
    "long_avg = longitude.longitude.mean()\n",
    "wells2.longitude.replace(0, long_avg, inplace=True)\n",
    "\n",
    "latitude = wells2.drop(wells2[wells2.latitude == -2.000000e-08].index) \n",
    "lat_avg = latitude.latitude.mean()\n",
    "wells2.latitude.replace(-2.000000e-08, lat_avg, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert target to binary\n",
    "To meet the business understanding of wells that require an engineer's evaluation, \"functional needs repair\" and \"non functional\" will be combined into \"needs work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells2.status_group = wells2.status_group.replace({'functional needs repair':'needs work',\n",
    "                                                  'non functional':'needs work'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells2.status_group = wells2.status_group.map({'functional': 1, 'needs work': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wells2.drop(['status_group'], axis=1)\n",
    "y = wells2['status_group']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpipes & Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines to properly scale / encode different data types for use in column transformer\n",
    "\n",
    "subpipe_num = Pipeline(steps=[('ss', StandardScaler())])\n",
    "\n",
    "subpipe_cat = Pipeline(steps=[('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "#subpipe_ord = Pipeline(steps=[('ord', OrdinalEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of features for each subpipe\n",
    "cat_feat = X_train.select_dtypes(include=['object']).columns\n",
    "num_feat = X_train.select_dtypes(include=['float', 'int64']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('subpipe_num', subpipe_num, num_feat),\n",
    "    ('subpipe_cat', subpipe_cat, cat_feat),\n",
    "    #('subpipe_ord', subpipe_ord, ord_feat)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Since water is so vital, the Tanzanian government wants to focus on identifying wells that need work.  The modeling process will aim to minimize the number of wells that are predicted to be functional, but actually need work (false positives).  Therefore precision will be used as the primary scoring metric with secondary consideration for accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pipeline to maintain consistency with later models, dummy strategy of most frequent to establlish a baseline\n",
    "\n",
    "dummy_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('dum', DummyClassifier(strategy='most_frequent', random_state=52))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['gps_height', 'longitude', 'latitude', 'population'], dtype='object')),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['wpt_name', 'basin', 'region', 'region_code', 'district_code', 'lga',\n",
       "       '...,\n",
       "       'extraction_type_group', 'extraction_type_class', 'management',\n",
       "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
       "       'source_class', 'waterpoint_type', 'waterpoint_type_group',\n",
       "       'year_recorded'],\n",
       "      dtype='object'))])),\n",
       "                ('dum',\n",
       "                 DummyClassifier(random_state=52, strategy='most_frequent'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54341189674523"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, dummy_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the precision score for the dummy classifier is not very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_pipe = Pipeline(steps=[\n",
    "    ('ct',ct),\n",
    "    ('dct', DecisionTreeClassifier(random_state=52))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['gps_height', 'longitude', 'latitude', 'population'], dtype='object')),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['wpt_name', 'basin', 'region', 'region_code', 'district_code', 'lga',\n",
       "       '..., 'extraction_type',\n",
       "       'extraction_type_group', 'extraction_type_class', 'management',\n",
       "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
       "       'source_class', 'waterpoint_type', 'waterpoint_type_group',\n",
       "       'year_recorded'],\n",
       "      dtype='object'))])),\n",
       "                ('dct', DecisionTreeClassifier(random_state=52))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999586845149562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, dct_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79899497, 0.79843562, 0.79498906, 0.80115676, 0.79644781])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dct_pipe, X_train, y_train, scoring='precision', error_score='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "The untuned decision tree model performs significantly better than the baseline, but not particularly great precision and very memory intensive.  May need to reduce number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(steps=[\n",
    "    ('ct',ct),\n",
    "    ('lr', LogisticRegression(random_state=52, max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['gps_height', 'longitude', 'latitude', 'population'], dtype='object')),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['wpt_name', 'basin', 'region', 'region_code', 'district_code', 'lga',\n",
       "       '...ion_type',\n",
       "       'extraction_type_group', 'extraction_type_class', 'management',\n",
       "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
       "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
       "       'source_class', 'waterpoint_type', 'waterpoint_type_group',\n",
       "       'year_recorded'],\n",
       "      dtype='object'))])),\n",
       "                ('lr', LogisticRegression(max_iter=1000, random_state=52))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78467153, 0.77428464, 0.7779879 , 0.78575477, 0.78854626])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr_pipe, X_train, y_train, scoring='precision', error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

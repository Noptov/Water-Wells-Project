{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells4 = pd.read_csv('data/wells4.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create well_age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells4['well_age'] = wells4.year_recorded - wells4.construction_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    59400.000000\n",
      "mean        15.042374\n",
      "std         10.100175\n",
      "min         -7.000000\n",
      "25%          8.000000\n",
      "50%         14.000000\n",
      "75%         16.000000\n",
      "max         53.000000\n",
      "Name: well_age, dtype: float64\n",
      "8729    -4\n",
      "10441   -2\n",
      "13366   -7\n",
      "23373   -5\n",
      "27501   -5\n",
      "32619   -1\n",
      "33942   -3\n",
      "39559   -5\n",
      "48555   -4\n",
      "Name: well_age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(wells4.well_age.describe())\n",
    "print(wells4.well_age.loc[lambda x : x<0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously it is not possible to have a well with a negative age.  Likely erroneous values in the original dataset for construction_year or date_recorded.  Since they are few in number, I will set the negative values to null and use a SimpleImputer in the Column Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells4.loc[wells4.well_age < 0, \"well_age\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Appropriate Numeric Columns to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells4[['construction_year', 'year_recorded']] = wells4[['construction_year', 'year_recorded']].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wells4.drop(['status_group'], axis=1)\n",
    "y = wells4['status_group']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subpipes & Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines to properly scale / encode different data types for use in column transformer\n",
    "\n",
    "subpipe_num = Pipeline(steps=[\n",
    "    ('num_impute', SimpleImputer()),\n",
    "    ('ss', StandardScaler())\n",
    "    ])\n",
    "\n",
    "subpipe_cat = Pipeline(steps=[('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))])\n",
    "\n",
    "#subpipe_ord = Pipeline(steps=[('ord', OrdinalEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of features for each subpipe\n",
    "cat_feat = X_train.select_dtypes(include=['object']).columns\n",
    "num_feat = X_train.select_dtypes(include=['float', 'int64']).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers = [\n",
    "    ('subpipe_num', subpipe_num, num_feat),\n",
    "    ('subpipe_cat', subpipe_cat, cat_feat),\n",
    "    #('subpipe_ord', subpipe_ord, ord_feat)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Since water is so vital, the Tanzanian government wants to focus on identifying wells that need work.  The modeling process will aim to minimize the number of wells that are predicted to be functional, but actually need work (false positives).  Therefore precision will be used as the primary scoring metric with secondary consideration for accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a pipeline to maintain consistency with later models, dummy strategy of most frequent to establlish a baseline\n",
    "\n",
    "dummy_pipe = Pipeline(steps=[\n",
    "    ('ct', ct),\n",
    "    ('dum', DummyClassifier(strategy='most_frequent', random_state=52))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['gps_height', 'longitude', 'latitude', 'population', 'well_age'], dtype='object')),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['basin', 'region', 'construction_year', 'extraction_type', 'management',\n",
       "       'water_quality', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type', 'year_recorded'],\n",
       "      dtype='object'))])),\n",
       "                ('dum',\n",
       "                 DummyClassifier(random_state=52, strategy='most_frequent'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54341189674523"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, dummy_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the precision score for the dummy classifier is not very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_pipe = Pipeline(steps=[\n",
    "    ('ct',ct),\n",
    "    ('dct', DecisionTreeClassifier(random_state=52))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['gps_height', 'longitude', 'latitude', 'population', 'well_age'], dtype='object')),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['basin', 'region', 'construction_year', 'extraction_type', 'management',\n",
       "       'water_quality', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type', 'year_recorded'],\n",
       "      dtype='object'))])),\n",
       "                ('dct', DecisionTreeClassifier(random_state=52))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946365211651126"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_train, dct_pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79621543, 0.78748718, 0.78698953, 0.79368729, 0.79621451])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dct_pipe, X_train, y_train, scoring='precision', error_score='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "The untuned decision tree model performs significantly better than the baseline, but not particularly great precision and significantly overfit. FSM was useful in identifying that some categoricals were causing it to run very slowly. Eliminated some features with further EDA and reran FSM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline(steps=[\n",
    "    ('ct',ct),\n",
    "    ('lr', LogisticRegression(random_state=52, max_iter=1000))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                  Pipeline(steps=[('num_impute',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('ss',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['gps_height', 'longitude', 'latitude', 'population', 'well_age'], dtype='object')),\n",
       "                                                 ('subpipe_cat',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  Index(['basin', 'region', 'construction_year', 'extraction_type', 'management',\n",
       "       'water_quality', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type', 'year_recorded'],\n",
       "      dtype='object'))])),\n",
       "                ('lr', LogisticRegression(max_iter=1000, random_state=52))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7231178 , 0.71530683, 0.71997912, 0.72472893, 0.72505699])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defaults and max iter=1000\n",
    "cross_val_score(lr_pipe, X_train, y_train, scoring='precision', error_score='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch \n",
    "Untuned LogReg underperformed it's DCT counterpart, trying Gridsearch to tune LogReg hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['lr__solver'] = ['newton-cg', 'lbfgs', 'saga']\n",
    "params['lr__C'] = [.25, .5, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=5, n_jobs=-2, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ct',\n",
       "                                        ColumnTransformer(transformers=[('subpipe_num',\n",
       "                                                                         Pipeline(steps=[('num_impute',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('ss',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         Index(['gps_height', 'longitude', 'latitude', 'population', 'well_age'], dtype='object')),\n",
       "                                                                        ('subpipe_cat',\n",
       "                                                                         Pipeline(steps=[('ohe',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         Index(['basin', 'region', 'construction_year', 'extraction_type', 'management',\n",
       "       'water_quality', 'quality_group', 'quantity', 'source',\n",
       "       'waterpoint_type', 'year_recorded'],\n",
       "      dtype='object'))])),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=52))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'lr__C': [0.25, 0.5, 1, 2],\n",
       "                         'lr__solver': ['newton-cg', 'lbfgs', 'saga']},\n",
       "             scoring='precision')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72124999, 0.72124027, 0.72128096, 0.72126113, 0.72130581,\n",
       "       0.72130621, 0.72166316, 0.72163793, 0.72163713, 0.72155984,\n",
       "       0.72147398, 0.72152267])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 1, 'lr__solver': 'newton-cg'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR Follow Up GridsearchCV\n",
    "Initial tuning had limited success.  Will try taking the best params and tweaking other hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['lr__solver'] = ['newton-cg']\n",
    "params['lr__C'] = [1, 2, 10]\n",
    "params['lr__penalty'] = ['l1', 'l2', 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=5, n_jobs=-2, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further review, the newton-cg solver does not support l1, hence the nan score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final attempt at tuning LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['lr__solver'] = ['newton-cg', 'liblinear']\n",
    "params['lr__C'] = [1, 10, 100]\n",
    "params['lr__penalty'] = ['l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1_2 = GridSearchCV(estimator=lr_pipe, param_grid=params, cv=5, n_jobs=-2, scoring='precision')\n",
    "gs1_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1_2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Improvement\n",
    "With virtually no improvement after three rounds of parameter tuning, LogReg does not appear to be a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 A Tuned DCT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3 = GridSearchCV(estimator=dct_pipe, param_grid=params, cv=5, n_jobs=-2, scoring='precision')\n",
    "\n",
    "params = {}\n",
    "params['dct__criterion'] = ['gini', 'entropy']\n",
    "params['dct__max_depth'] = [5, 10, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second tune\n",
    "Scores were actually down slightly from the untuned DCT and the max_depth choose the highest value, so I will try rerunning with higher values for that param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_2 = GridSearchCV(estimator=dct_pipe, param_grid=params, cv=5, n_jobs=-2, scoring='precision')\n",
    "\n",
    "params = {}\n",
    "params['dct__criterion'] = ['gini', 'entropy']\n",
    "params['dct__max_depth'] = [25, 52, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_2.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Tune\n",
    "The best DCT params so far are gini and max_depth 25.  Will keep those and try them with other params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_3 = GridSearchCV(estimator=dct_pipe, param_grid=params, cv=5, n_jobs=-3, scoring='precision')\n",
    "\n",
    "params = {}\n",
    "params['dct__criterion'] = ['gini']\n",
    "params['dct__max_depth'] = [25]\n",
    "params['dct__min_sample_leaf'] = [5, 10, 20]\n",
    "params['dct__min_impurity_decrease'] = [0, .1, 1, 5]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_3.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
